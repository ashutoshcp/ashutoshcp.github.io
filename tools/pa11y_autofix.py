#!/usr/bin/env python3
"""
Simple pa11y JSON auto-fixer.

Usage:
  python3 tools/pa11y_autofix.py --report pa11y-report.json [--root .]

What it does (safe, conservative):
- Parses a pa11y JSON report (use `pa11y --reporter json`) and applies conservative fixes to HTML files in the repo:
  - Add alt="" to <img> elements missing alt attributes (can't invent descriptive text).
  - Add aria-label to empty links (<a>) that contain only icons and no accessible name (derives label from href hostname/path).
- Backs up each edited file to <file>.pa11y-autofix.bak.
- Prints a summary of changes.

Notes:
- This tool is intentionally conservative: it will not write meaningful alt text (that requires human input).
- Always review changes and replace autogenerated alt="" with descriptive text.

"""
import argparse
import json
import os
import sys
from urllib.parse import urlparse

try:
    from bs4 import BeautifulSoup
except Exception:
    print("BeautifulSoup not found. Please install with: pip3 install --user beautifulsoup4")
    sys.exit(1)


def local_path_from_pageurl(root, page_url):
    """Map a pa11y pageUrl to a local file path under root.
    Examples:
      http://localhost:8000/ -> index.html
      http://localhost:8000/about.html -> about.html
    """
    parsed = urlparse(page_url)
    path = parsed.path
    if not path or path == '/':
        candidate = os.path.join(root, 'index.html')
    else:
        # strip leading '/'
        candidate = os.path.join(root, path.lstrip('/'))
    return candidate


def ensure_backup(path):
    bak = path + '.pa11y-autofix.bak'
    if not os.path.exists(bak):
        with open(path, 'rb') as fsrc, open(bak, 'wb') as fdst:
            fdst.write(fsrc.read())
    return bak


def derive_label_from_href(href):
    try:
        p = urlparse(href)
        host = p.netloc
        if host:
            # use host (github.com) or last path segment if more descriptive
            seg = p.path.rstrip('/').split('/')[-1]
            if seg:
                return seg.replace('-', ' ').replace('_', ' ')
            return host
        # fallback: use href
        return href
    except Exception:
        return href


def apply_fixes_to_file(path, fixes):
    with open(path, 'r', encoding='utf-8') as f:
        html = f.read()
    soup = BeautifulSoup(html, 'html.parser')
    changed = False
    details = []

    for fix in fixes:
        selector = fix.get('selector')
        code = fix.get('code')
        context = fix.get('context')
        if not selector:
            continue
        elements = soup.select(selector)
        if not elements:
            # sometimes pa11y gives context snippet instead of selector; skip
            continue
        for el in elements:
            if el.name == 'img' and not el.has_attr('alt'):
                el['alt'] = ''
                el['data-pa11y-autofix'] = 'alt-empty-added'
                el['data-pa11y-context'] = context[:200]
                changed = True
                details.append((selector, 'img alt added'))
            elif el.name == 'a':
                txt = el.get_text(strip=True)
                has_label = el.has_attr('aria-label') or el.has_attr('title')
                if txt == '' and not has_label:
                    href = el.get('href', '')
                    label = derive_label_from_href(href) or 'link'
                    el['aria-label'] = label
                    el['data-pa11y-autofix'] = 'aria-label-added'
                    el['data-pa11y-context'] = context[:200]
                    changed = True
                    details.append((selector, f'aria-label added: "{label}"'))
            # Add more heuristics here as needed
    if changed:
        ensure_backup(path)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(str(soup))
    return changed, details


def main():
    parser = argparse.ArgumentParser(description='Conservative pa11y JSON auto-fixer')
    parser.add_argument('--report', required=True, help='Path to pa11y JSON report (use pa11y --reporter json)')
    parser.add_argument('--root', default='.', help='Repo root (where index.html lives)')
    args = parser.parse_args()

    if not os.path.exists(args.report):
        print('Report not found:', args.report)
        sys.exit(2)

    with open(args.report, 'r', encoding='utf-8') as f:
        try:
            report = json.load(f)
        except Exception as e:
            print('Failed to parse JSON report:', e)
            sys.exit(3)

    # pa11y json reporter returns an array for a single page or an array of results
    # It may also include pageUrl fields. We'll group results by pageUrl.
    pages = {}
    for item in report:
        page = item.get('pageUrl') or item.get('context') or '/'  # fallback
        pages.setdefault(page, []).append(item)

    summary = {}
    for page_url, items in pages.items():
        local = local_path_from_pageurl(args.root, page_url)
        if not os.path.exists(local):
            # try fallback: if page_url is just a path
            if page_url.startswith('/'):
                try_local = os.path.join(args.root, page_url.lstrip('/'))
                if os.path.exists(try_local):
                    local = try_local
            if not os.path.exists(local):
                print('Skipping (local file not found) for pageUrl:', page_url, 'mapped to', local)
                continue
        # Prepare fixes list (we pass full items but keep only selector/context)
        fixes = []
        for it in items:
            fixes.append({'selector': it.get('selector'), 'code': it.get('code'), 'context': it.get('context')})
        changed, details = apply_fixes_to_file(local, fixes)
        summary[local] = details

    print('\nAuto-fix summary:')
    for fpath, details in summary.items():
        if details:
            print('-', fpath)
            for d in details:
                print('   *', d[0], '->', d[1])
        else:
            print('-', fpath, '(no auto-fixes applied)')

    print('\nBackups created with .pa11y-autofix.bak suffix for edited files. Please review changes.')

if __name__ == '__main__':
    main()

